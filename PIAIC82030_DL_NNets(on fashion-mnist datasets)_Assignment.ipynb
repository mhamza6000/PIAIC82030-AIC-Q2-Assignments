{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including Essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset insights such as shape and count of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of images:  (60000, 784) , Number of images:  60000 , Number of labels:  60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "shape_len = lambda x,y: print(\"shape of images: \", x.shape,\", Number of images: \", len(x), \", Number of labels: \",len(y))\n",
    "shape_len(train_images,train_labels)\n",
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(Dense(512,activation='relu',input_shape=(28*28,)))\n",
    "network.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Optimizer, Loss Function and Performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting numerical vector to binary class matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural network on training portion of the fashion-mnist dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 4s 102us/sample - loss: 0.7062 - accuracy: 0.7552 - val_loss: 0.4918 - val_accuracy: 0.8258\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.4638 - accuracy: 0.8324 - val_loss: 0.4083 - val_accuracy: 0.8502\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.4039 - accuracy: 0.8527 - val_loss: 0.4390 - val_accuracy: 0.8406\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.3600 - accuracy: 0.8664 - val_loss: 0.3773 - val_accuracy: 0.8618\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.3358 - accuracy: 0.8760 - val_loss: 0.4005 - val_accuracy: 0.8560\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.3146 - accuracy: 0.8850 - val_loss: 0.3222 - val_accuracy: 0.8834\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.2981 - accuracy: 0.8881 - val_loss: 0.3304 - val_accuracy: 0.8807\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.2811 - accuracy: 0.8947 - val_loss: 0.3432 - val_accuracy: 0.8744\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 3s 61us/sample - loss: 0.2701 - accuracy: 0.8997 - val_loss: 0.3333 - val_accuracy: 0.8799\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.2561 - accuracy: 0.9042 - val_loss: 0.3289 - val_accuracy: 0.8827\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.2497 - accuracy: 0.9073 - val_loss: 0.3098 - val_accuracy: 0.8898\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.2371 - accuracy: 0.9113 - val_loss: 0.3253 - val_accuracy: 0.8842\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.2287 - accuracy: 0.9145 - val_loss: 0.3096 - val_accuracy: 0.8912\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.2227 - accuracy: 0.9165 - val_loss: 0.2960 - val_accuracy: 0.8957\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.2124 - accuracy: 0.9202 - val_loss: 0.3236 - val_accuracy: 0.8858\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.2064 - accuracy: 0.9214 - val_loss: 0.3113 - val_accuracy: 0.8911\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.1993 - accuracy: 0.9269 - val_loss: 0.3203 - val_accuracy: 0.8912\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.1919 - accuracy: 0.9275 - val_loss: 0.3182 - val_accuracy: 0.8906\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.1853 - accuracy: 0.9300 - val_loss: 0.3185 - val_accuracy: 0.8937\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.1817 - accuracy: 0.9319 - val_loss: 0.3177 - val_accuracy: 0.8904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x250a69a68c8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images,train_labels,epochs=20,batch_size=300,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the trained network on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s - loss: 0.2450 - accuracy: 0.8912\n",
      "test_acc: 0.8912 test_loss: 0.31829351351261137\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels,verbose=2)\n",
    "print('test_acc:', test_acc,'test_loss:',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
